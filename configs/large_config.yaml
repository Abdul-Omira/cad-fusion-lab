# Text-to-CAD Large Configuration
# High-capacity model for production-quality results

# Model Architecture
model:
  vocab_size: 10000
  text_encoder_name: "bert-large-uncased"  # Upgraded from base
  d_model: 1024                            # Increased from 512
  nhead: 16                                # Increased from 8
  num_decoder_layers: 32                   # Increased from 24
  dim_feedforward: 4096                    # Increased from 2048
  dropout: 0.1
  max_seq_length: 768                      # Increased from 512

# Training Parameters
training:
  batch_size: 32                           # Decreased from 64 to fit in memory
  learning_rate: 5.0e-5                    # Decreased for more stable training
  weight_decay: 0.01
  max_grad_norm: 1.0
  warmup_steps: 2000                       # Increased from 1000
  num_epochs: 30                           # Increased from 20
  save_interval: 1
  log_interval: 50
  gradient_accumulation_steps: 2           # Added for larger effective batch size
  
# Visual Feedback Parameters
visual_feedback:
  clip_model_name: "openai/clip-vit-large-patch14"  # Upgraded from base
  clip_weight: 1.0
  geometry_weight: 0.5
  chamfer_weight: 0.1

# PPO Fine-tuning
ppo:
  enabled: true
  ppo_epochs: 5
  clip_ratio: 0.2
  value_loss_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  
# Geometric Validation
validation:
  min_thickness: 0.5
  check_topology: true
  check_self_intersection: true            # Added for enhanced validation
  check_watertightness: true               # Added for enhanced validation
  
# Data Processing
data:
  train_cad_path: "data/processed/train.json"
  train_text_path: "data/annotations/train.json"
  val_cad_path: "data/processed/val.json"
  val_text_path: "data/annotations/val.json"
  test_cad_path: "data/processed/test.json" 
  test_text_path: "data/annotations/test.json"
  augmentation: true                       # Added data augmentation
  
# Logging & Evaluation
logging:
  use_wandb: true
  wandb_project: "text-to-cad-large"
  log_dir: "outputs/logs"
  save_best_only: true                      # Only save best checkpoints
  
# Inference
inference:
  temperature: 0.7                          # More focused generation
  top_k: 40
  top_p: 0.95
  max_length: 768
  beam_size: 5                              # Added beam search for better results
  
# Deployment
deployment:
  quantization: "FP16"
  device: "cuda"
  batch_size: 1
  timeout: 30.0
  port: 8000
  precision: "mixed"                        # Added mixed precision for better performance
  num_workers: 4                            # Parallel workers for serving
  
# Advanced Features  
advanced:
  use_mixed_precision: true                 # Enable mixed precision training
  parameter_sharing: "layerwise"            # Parameter sharing strategy
  activation: "gelu"                        # Activation function
  critical_bits: 12                         # 12-bit precision for critical dimensions